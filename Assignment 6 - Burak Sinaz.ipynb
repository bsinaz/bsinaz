{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords, reuters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "stop_words = stopwords.words(\"english\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"/case/wiki_movie.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1903</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>American</td>\n",
       "      <td>Cecil Hepworth</td>\n",
       "      <td>May Clark</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_in_Wonderl...</td>\n",
       "      <td>Alice follows a large white rabbit down a \"Rab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1903</td>\n",
       "      <td>The Great Train Robbery</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>western</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Great_Train_...</td>\n",
       "      <td>The film opens with two bandits breaking into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904</td>\n",
       "      <td>The Suburbanite</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace McCutcheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Suburbanite</td>\n",
       "      <td>The film is about a family who move to the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1905</td>\n",
       "      <td>The Little Train Robbery</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin Stanton Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Little_Train...</td>\n",
       "      <td>The opening scene shows the interior of the ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1905</td>\n",
       "      <td>The Night Before Christmas</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin Stanton Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Night_Before...</td>\n",
       "      <td>Scenes are introduced using lines of the poem....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                             Title Origin/Ethnicity  \\\n",
       "0          1901            Kansas Saloon Smashers         American   \n",
       "1          1901     Love by the Light of the Moon         American   \n",
       "2          1901           The Martyred Presidents         American   \n",
       "3          1901  Terrible Teddy, the Grizzly King         American   \n",
       "4          1902            Jack and the Beanstalk         American   \n",
       "5          1903               Alice in Wonderland         American   \n",
       "6          1903           The Great Train Robbery         American   \n",
       "7          1904                   The Suburbanite         American   \n",
       "8          1905          The Little Train Robbery         American   \n",
       "9          1905        The Night Before Christmas         American   \n",
       "\n",
       "                             Director       Cast    Genre  \\\n",
       "0                             Unknown        NaN  unknown   \n",
       "1                             Unknown        NaN  unknown   \n",
       "2                             Unknown        NaN  unknown   \n",
       "3                             Unknown        NaN  unknown   \n",
       "4  George S. Fleming, Edwin S. Porter        NaN  unknown   \n",
       "5                      Cecil Hepworth  May Clark  unknown   \n",
       "6                     Edwin S. Porter        NaN  western   \n",
       "7                  Wallace McCutcheon        NaN   comedy   \n",
       "8                Edwin Stanton Porter        NaN  unknown   \n",
       "9                Edwin Stanton Porter        NaN  unknown   \n",
       "\n",
       "                                           Wiki Page  \\\n",
       "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "5  https://en.wikipedia.org/wiki/Alice_in_Wonderl...   \n",
       "6  https://en.wikipedia.org/wiki/The_Great_Train_...   \n",
       "7      https://en.wikipedia.org/wiki/The_Suburbanite   \n",
       "8  https://en.wikipedia.org/wiki/The_Little_Train...   \n",
       "9  https://en.wikipedia.org/wiki/The_Night_Before...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  \n",
       "3  Lasting just 61 seconds and consisting of two ...  \n",
       "4  The earliest known adaptation of the classic f...  \n",
       "5  Alice follows a large white rabbit down a \"Rab...  \n",
       "6  The film opens with two bandits breaking into ...  \n",
       "7  The film is about a family who move to the sub...  \n",
       "8  The opening scene shows the interior of the ro...  \n",
       "9  Scenes are introduced using lines of the poem....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "American        17377\n",
       "British          3670\n",
       "Bollywood        2931\n",
       "Tamil            2599\n",
       "Telugu           1311\n",
       "Japanese         1188\n",
       "Malayalam        1095\n",
       "Hong Kong         791\n",
       "Canadian          723\n",
       "Australian        576\n",
       "South_Korean      522\n",
       "Chinese           463\n",
       "Kannada           444\n",
       "Bengali           306\n",
       "Russian           232\n",
       "Marathi           141\n",
       "Filipino          128\n",
       "Bangladeshi        87\n",
       "Punjabi            84\n",
       "Turkish            70\n",
       "Malaysian          70\n",
       "Egyptian           67\n",
       "Assamese            9\n",
       "Maldivian           2\n",
       "Name: Origin/Ethnicity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Origin/Ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A bartender is working at a saloon, serving drinks to customers. After he fills a stereotypically Irish man's bucket with beer, Carrie Nation and her followers burst inside. They assault the Irish man, pulling his hat over his eyes and then dumping the beer over his head. The group then begin wrecking the bar, smashing the fixtures, mirrors, and breaking the cash register. The bartender then sprays seltzer water in Nation's face before a group of policemen appear and order everybody to leave.[1]\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_swords(txt_data):\n",
    "    txt_clean = [word for word in text_data if word not in stopwords]\n",
    "    return txt_clean\n",
    "\n",
    "data['plot_no_sw'] = data['Plot'].apply(lambda x: remove_stopwords(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Count Vectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", max_features = 20, max_df=0.3)\n",
    "count_model = vectorizer.fit(data[\"Plot\"])\n",
    "X = count_model.transform(data[\"Plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['being',\n",
       " 'can',\n",
       " 'day',\n",
       " 'family',\n",
       " 'father',\n",
       " 'find',\n",
       " 'finds',\n",
       " 'goes',\n",
       " 'had',\n",
       " 'home',\n",
       " 'house',\n",
       " 'however',\n",
       " 'man',\n",
       " 'mother',\n",
       " 'new',\n",
       " 'off',\n",
       " 'police',\n",
       " 'so',\n",
       " 'tells',\n",
       " 'wife']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 9, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfidf Vectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer = \"word\", max_features = 20, max_df=0.3)\n",
    "tfidf_model = vectorizer.fit(data[\"Plot\"])\n",
    "X = tfidf_model.transform(data[\"Plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['being',\n",
       " 'can',\n",
       " 'day',\n",
       " 'family',\n",
       " 'father',\n",
       " 'find',\n",
       " 'finds',\n",
       " 'goes',\n",
       " 'had',\n",
       " 'home',\n",
       " 'house',\n",
       " 'however',\n",
       " 'man',\n",
       " 'mother',\n",
       " 'new',\n",
       " 'off',\n",
       " 'police',\n",
       " 'so',\n",
       " 'tells',\n",
       " 'wife']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.31929371, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.61645448, 0.        , 0.        , 0.62735701,\n",
       "         0.        , 0.        , 0.        , 0.35278689, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\burak\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    American       0.67      0.96      0.79      1752\n",
      "  Australian       0.50      0.03      0.05        40\n",
      " Bangladeshi       0.00      0.00      0.00        10\n",
      "     Bengali       0.00      0.00      0.00        26\n",
      "   Bollywood       0.56      0.56      0.56       315\n",
      "     British       0.53      0.24      0.33       372\n",
      "    Canadian       0.00      0.00      0.00        79\n",
      "     Chinese       0.00      0.00      0.00        43\n",
      "    Egyptian       0.00      0.00      0.00         4\n",
      "    Filipino       0.00      0.00      0.00        15\n",
      "   Hong Kong       0.71      0.16      0.26        74\n",
      "    Japanese       0.68      0.20      0.31       129\n",
      "     Kannada       0.00      0.00      0.00        43\n",
      "   Malayalam       0.39      0.16      0.23       100\n",
      "   Malaysian       0.00      0.00      0.00         4\n",
      "     Marathi       0.00      0.00      0.00        18\n",
      "     Punjabi       0.00      0.00      0.00         9\n",
      "     Russian       0.00      0.00      0.00        22\n",
      "South_Korean       0.43      0.07      0.12        45\n",
      "       Tamil       0.41      0.52      0.46       242\n",
      "      Telugu       0.70      0.37      0.48       138\n",
      "     Turkish       0.00      0.00      0.00         9\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      3489\n",
      "   macro avg       0.25      0.15      0.16      3489\n",
      "weighted avg       0.56      0.63      0.56      3489\n",
      "\n",
      "[[1688    0    0    0   13   42    1    0    0    0    1    3    0    0\n",
      "     0    0    0    0    1    3    0    0]\n",
      " [  35    1    0    0    1    1    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    2    0    0]\n",
      " [   3    0    0    0    2    2    0    0    0    0    0    0    0    1\n",
      "     0    0    0    0    0    2    0    0]\n",
      " [  11    0    0    0    6    1    0    0    0    0    0    0    0    2\n",
      "     0    0    0    0    1    4    1    0]\n",
      " [  72    0    0    0  177    8    0    0    0    0    1    1    0    5\n",
      "     0    0    0    0    1   45    5    0]\n",
      " [ 279    0    0    0    1   88    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    3    1    0]\n",
      " [  74    0    0    0    1    1    0    0    0    0    1    0    0    0\n",
      "     0    0    0    0    0    2    0    0]\n",
      " [  31    0    0    0    1    5    0    0    0    0    1    3    0    0\n",
      "     0    0    0    0    1    1    0    0]\n",
      " [   1    0    0    0    2    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    1    0    0]\n",
      " [  13    0    0    0    1    0    0    0    0    0    0    0    0    1\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  56    0    0    0    0    2    0    0    0    0   12    2    0    0\n",
      "     0    0    0    0    0    2    0    0]\n",
      " [  94    0    0    0    2    3    0    0    0    0    1   26    0    0\n",
      "     0    0    0    0    0    3    0    0]\n",
      " [   3    0    0    0   12    0    0    0    0    0    0    0    0    2\n",
      "     0    0    0    0    0   23    3    0]\n",
      " [  28    0    0    0   16    1    0    0    0    0    0    1    0   16\n",
      "     0    0    0    0    0   36    2    0]\n",
      " [   4    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   6    0    0    0    5    2    0    0    0    0    0    0    0    2\n",
      "     0    0    0    0    0    3    0    0]\n",
      " [   2    0    0    0    6    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    1    0    0]\n",
      " [  15    1    0    0    0    4    0    0    0    0    0    0    0    2\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  28    0    0    0    3    2    0    0    0    0    0    1    0    4\n",
      "     0    0    0    0    3    4    0    0]\n",
      " [  55    0    0    0   45    1    0    0    0    0    0    1    0    5\n",
      "     0    0    0    0    0  125   10    0]\n",
      " [  18    0    0    0   21    0    0    0    0    0    0    0    0    1\n",
      "     0    0    0    0    0   47   51    0]\n",
      " [   7    0    0    0    0    2    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\burak\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer = \"word\", max_features = 1000)\n",
    "tfidf_model = vectorizer.fit(data[\"Plot\"])\n",
    "pickle.dump(tfidf_model, open(\"/case/tfidf.pkl\", \"wb\"))\n",
    "X = tfidf_model.transform(data[\"Plot\"])\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,data[\"Origin/Ethnicity\"],test_size = 0.1)\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n",
    "pickle.dump(clf, open(\"/case/text_clf.pkl\", 'wb'))\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf_model = pickle.load(open(\"case/tfidf.pkl\", 'rb'))\n",
    "\n",
    "new_data = [\"\"]\n",
    "X = tfidf_model.transform(new_data)\n",
    "loaded_clf = pickle.load(open(\"case/text_clf.pkl\", 'rb'))\n",
    "preds = loaded_clf.predict_proba(X)\n",
    "print(loaded_clf.classes_)\n",
    "print(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
